{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we will be using a large dataset of Twitter reviews for US Airlines, which are classified into three categories: positive, negative, or neutral. Our goal is to train a model based on this dataset to determine sentiments, i.e. positive, negative, or neutral, of new tweets on Airlines.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "The standard libraies are loaded.\n",
    "\n",
    "The data is first loaded using `pd.read_csv()`. Then the two columns `text` annd `airline_sentiment` are extracted from the file and stored in `df2`. \n",
    "We only want to analyze the tweets that have a 100% confidence from the dataset. The texts are stored separately in an array, `df2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('Twitter_analysis_sentiment.csv')\n",
    "df2 = df[['text','airline_sentiment']]\n",
    "# the tweets we are using are those labelled with 100% confidence\n",
    "df2 = df2[df['airline_sentiment_confidence'] == 1]\n",
    "textArray = np.array(df2['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize Tweets\n",
    "Here the class `CountVectorizer` is imported from `sklearn` along with the library `nltk` in order to tokenize the text. CountVectorizer allows us to convert a collection of text into a matrix of token counts- the frequency of occurance of the words in each line.\n",
    "\n",
    "The array of text is transformed using the `CountVectorizer` with `min_df=2` and `tokenizer = nltk.word_tokenize` and stored in `tweet_counts`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10445, 5442)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "tweet_vec = CountVectorizer(min_df=2, tokenizer=nltk.word_tokenize) \n",
    "tweet_counts = tweet_vec.fit_transform(textArray)\n",
    "print(tweet_counts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TF-IDF Vector\n",
    "Next the class `TfidfTransformer` is imported from `sklearn`. Like with CountVectorizer, TfidfTransformer is stored in a variable, `tfidf_transformer` and is used to fit the tweet_counts. \n",
    "\n",
    "`TfidfTransformer` converts the count matrix to a tf-idf representation ora  term-frequency times inverse document-frequency. This gives a weighing factor to the counts to reduce the impact of words that occur frequently in a corpus and would be less informative than other words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10445, 5442)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tweet_tfidf = tfidf_transformer.fit_transform(tweet_counts)\n",
    "print(tweet_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Target Vector\n",
    "We create `target` vector to map the `positive` comments as `1` and `negative` comments as `-1` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map negative to -1, positve to 1, and neutral to 0\n",
    "target = np.zeros(textArray.shape[0])\n",
    "target[df2['airline_sentiment'] == 'positive'] = 1\n",
    "target[df2['airline_sentiment'] == 'negative'] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SVM from SKlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use k-fold cross validation\n",
    "We will first use the SVM method to classify the data. K-fold cross validation is used to train and test the data. The data is first shuffled before going throught the cross-validation in order to not be training consecutive tweets about one airline since the dataset is organized by airlines. \n",
    "\n",
    "The cross vaidation is ran for `10 folds`. After the cross-validation, the `confusion matrix` is also created by using `confusion_matrix` from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svc = svm.SVC(probability=False,  kernel=\"rbf\", C=2.8, gamma=.0073,verbose=10)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "nfold = 10 \n",
    "kf = KFold(n_splits=nfold, shuffle = True)\n",
    "C = np.zeros([3, 3])\n",
    "acc = []\n",
    "i = 0\n",
    "for train, test in kf.split(tweet_tfidf):\n",
    "    i = i+1\n",
    "    Xtr = tweet_tfidf[train,:]\n",
    "    ytr = target[train]\n",
    "    Xts = tweet_tfidf[test,:]\n",
    "    yts = target[test] \n",
    "    \n",
    "    svc.fit(Xtr,ytr) \n",
    "    yhat = svc.predict(Xts)\n",
    "    C = C + confusion_matrix(yts, yhat, labels=[1,-1,0])\n",
    "    acci = np.mean(yhat == yts)\n",
    "    acc.append(acci)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix and Accuracy\n",
    "The accuracy of the SVM classifier is determined along with the standard error and the confusion matrix is printed. The SVM method provided an accuracy of around `75%` with most of the comment being negative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = \n",
      "[[ 418. 1096.    1.]\n",
      " [   3. 7378.    1.]\n",
      " [  10. 1506.   32.]]\n",
      "Cm = \n",
      "[[0.2759 0.7234 0.0007]\n",
      " [0.0004 0.9995 0.0001]\n",
      " [0.0065 0.9729 0.0207]]\n",
      "Accuracy =  0.7495, SE=0.0063\n"
     ]
    }
   ],
   "source": [
    "accm= np.mean(acc) \n",
    "acc_se = np.std(acc)/np.sqrt(nfold-1)\n",
    "Cm = C / np.sum(C, axis = 1)[:,None] \n",
    "print('C = ')\n",
    "print(np.array_str(C, precision=4, suppress_small=True))\n",
    "print('Cm = ')\n",
    "print(np.array_str(Cm, precision=4, suppress_small=True))\n",
    "print('Accuracy =  {0:.4f}, SE={1:.4f}'.format(accm, acc_se)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Multinomial Naive Bayes Classifier from SKlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use k-fold cross validation\n",
    "Next, we also used the more commonly used text classifier, the `Multinomial Naive Bayes` Classifier from sklearn. This classifier uses the `Bayes's theorem` of probability in order to determine the probability the given parameter is likely to be closer to the specified fields. \n",
    "\n",
    "The tweets are shuffled and ran through the K-cross validation. The accuracy vector and confusion matrix is also created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nfold = 10 \n",
    "kf = KFold(n_splits=nfold, shuffle = True)\n",
    "C = np.zeros([3, 3])\n",
    "acc = []\n",
    "i = 0\n",
    "for train, test in kf.split(tweet_tfidf):\n",
    "    i = i+1\n",
    "    Xtr = tweet_tfidf[train,:]\n",
    "    ytr = target[train]\n",
    "    Xts = tweet_tfidf[test,:]\n",
    "    yts = target[test] \n",
    "    clf = MultinomialNB().fit(Xtr,ytr)\n",
    "    yhat = clf.predict(Xts)\n",
    "    C = C + confusion_matrix(yts, yhat, labels=[1,-1,0])\n",
    "    acci = np.mean(yhat == yts)\n",
    "    acc.append(acci)\n",
    "   # print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix and Accuracy\n",
    "Finally, the confusion matrix and accuracy of the Naive Bayes Classifier is printed. This method gave an accuracy of around `77%` (slightly better compared to the SVM method). \n",
    "\n",
    "Like with the SVM method, the confusion matrix shows that most of the comments were accurately predicted as negative (since most of the tweets were negative. Also like the SVM method, most of the tweets were also predicted as negative then it was neutral, so both methods have problems with distincting accurately negative and neutral sentiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = \n",
      "[[ 450. 1058.    7.]\n",
      " [   0. 7372.   10.]\n",
      " [  19. 1284.  245.]]\n",
      "Cm = \n",
      "[[0.297  0.6983 0.0046]\n",
      " [0.     0.9986 0.0014]\n",
      " [0.0123 0.8295 0.1583]]\n",
      "Accuracy =  0.7723, SE=0.0046\n"
     ]
    }
   ],
   "source": [
    "accm= np.mean(acc) \n",
    "acc_se = np.std(acc)/np.sqrt(nfold-1)\n",
    "Cm = C / np.sum(C, axis = 1)[:,None] \n",
    "print('C = ')\n",
    "print(np.array_str(C, precision=4, suppress_small=True))\n",
    "print('Cm = ')\n",
    "print(np.array_str(Cm, precision=4, suppress_small=True))\n",
    "print('Accuracy =  {0:.4f}, SE={1:.4f}'.format(accm, acc_se)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
