{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we will be using a large dataset of Twitter reviews for US Airlines, which are classified into three categories: positive, negative, or neutral. Our goal is to train a model based on this dataset to determine sentiments, i.e. positive, negative, or neutral, of new tweets on Airlines.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('Tweets.csv')\n",
    "df2 = df[['text','airline_sentiment']]\n",
    "# the tweets we are using are those labelled with 100% confidence\n",
    "df2 = df2[df['airline_sentiment_confidence'] == 1]\n",
    "textArray = np.array(df2['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10445, 5442)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "tweet_vec = CountVectorizer(min_df=2, tokenizer=nltk.word_tokenize) \n",
    "tweet_counts = tweet_vec.fit_transform(textArray)\n",
    "print(tweet_counts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TF-IDF Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10445, 5442)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tweet_tfidf = tfidf_transformer.fit_transform(tweet_counts)\n",
    "print(tweet_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Target Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map negative to -1, positve to 1, and neutral to 0\n",
    "target = np.zeros(textArray.shape[0])\n",
    "target[df2['airline_sentiment'] == 'positive'] = 1\n",
    "target[df2['airline_sentiment'] == 'negative'] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SVM from SKlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]1\n",
      "[LibSVM]2\n",
      "[LibSVM]3\n",
      "[LibSVM]4\n",
      "[LibSVM]5\n",
      "[LibSVM]6\n",
      "[LibSVM]7\n",
      "[LibSVM]8\n",
      "[LibSVM]9\n",
      "[LibSVM]10\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svc = svm.SVC(probability=False,  kernel=\"rbf\", C=2.8, gamma=.0073,verbose=10)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "nfold = 10 \n",
    "kf = KFold(n_splits=nfold, shuffle = True)\n",
    "C = np.zeros([3, 3])\n",
    "acc = []\n",
    "i = 0\n",
    "for train, test in kf.split(tweet_tfidf):\n",
    "    i = i+1\n",
    "    Xtr = tweet_tfidf[train,:]\n",
    "    ytr = target[train]\n",
    "    Xts = tweet_tfidf[test,:]\n",
    "    yts = target[test] \n",
    "    \n",
    "    svc.fit(Xtr,ytr) \n",
    "    yhat = svc.predict(Xts)\n",
    "    C = C + confusion_matrix(yts, yhat, labels=[1,-1,0])\n",
    "    acci = np.mean(yhat == yts)\n",
    "    acc.append(acci)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = \n",
      "[[ 420. 1094.    1.]\n",
      " [   3. 7378.    1.]\n",
      " [  11. 1499.   38.]]\n",
      "Cm = \n",
      "[[0.2772 0.7221 0.0007]\n",
      " [0.0004 0.9995 0.0001]\n",
      " [0.0071 0.9683 0.0245]]\n",
      "Accuracy =  0.7502, SE=0.0034\n"
     ]
    }
   ],
   "source": [
    "accm= np.mean(acc) \n",
    "acc_se = np.std(acc)/np.sqrt(nfold-1)\n",
    "Cm = C / np.sum(C, axis = 1)[:,None] \n",
    "print('C = ')\n",
    "print(np.array_str(C, precision=4, suppress_small=True))\n",
    "print('Cm = ')\n",
    "print(np.array_str(Cm, precision=4, suppress_small=True))\n",
    "print('Accuracy =  {0:.4f}, SE={1:.4f}'.format(accm, acc_se)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Multinomial Naive Bayes Classifier from SKlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nfold = 10 \n",
    "kf = KFold(n_splits=nfold, shuffle = True)\n",
    "C = np.zeros([3, 3])\n",
    "acc = []\n",
    "i = 0\n",
    "for train, test in kf.split(tweet_tfidf):\n",
    "    i = i+1\n",
    "    Xtr = tweet_tfidf[train,:]\n",
    "    ytr = target[train]\n",
    "    Xts = tweet_tfidf[test,:]\n",
    "    yts = target[test] \n",
    "    clf = MultinomialNB().fit(Xtr,ytr)\n",
    "    yhat = clf.predict(Xts)\n",
    "    C = C + confusion_matrix(yts, yhat, labels=[1,-1,0])\n",
    "    acci = np.mean(yhat == yts)\n",
    "    acc.append(acci)\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = \n",
      "[[ 450. 1058.    7.]\n",
      " [   1. 7371.   10.]\n",
      " [  18. 1276.  254.]]\n",
      "Cm = \n",
      "[[0.297  0.6983 0.0046]\n",
      " [0.0001 0.9985 0.0014]\n",
      " [0.0116 0.8243 0.1641]]\n",
      "Accuracy =  0.7731, SE=0.0052\n"
     ]
    }
   ],
   "source": [
    "accm= np.mean(acc) \n",
    "acc_se = np.std(acc)/np.sqrt(nfold-1)\n",
    "Cm = C / np.sum(C, axis = 1)[:,None] \n",
    "print('C = ')\n",
    "print(np.array_str(C, precision=4, suppress_small=True))\n",
    "print('Cm = ')\n",
    "print(np.array_str(Cm, precision=4, suppress_small=True))\n",
    "print('Accuracy =  {0:.4f}, SE={1:.4f}'.format(accm, acc_se)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
